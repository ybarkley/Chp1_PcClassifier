g---
title: "False Killer Whale Whistle Classification- Random Forest Analysis"
author: "Yvonne Barkley"
date: "August 29, 2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

#Load libraries
```{r warning=FALSE, message=FALSE}
library(sqldf)
library(randomForest)
library(partykit)
library(caret)
library(corrplot)
library(parallel); 
library(doParallel);
library(gtools)
library(devtools) 
library(dplyr)
#library(ROCR)
library(Hmisc)
library(tree)

```

First, clean up the raw ROCCA file
```{r}
#Load ROCCA data (already replaced 'NA' and '999' with '0')

#6/28/2018
#8/9/2018
#ROCCAdata<-read.csv('C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\2017- 100 New Whistles/ROCCA Towed Data//BigRoccaFile_PMN_TowedAll_RAW_20180816 - Copy.csv')

#8/29/18
ROCCAdata<-read.csv('C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\2017- 100 New Whistles/ROCCA Towed Data//BigRoccaFile_PMN_TowedAll_EDIT_20180816 - Copy.csv')

#Add species names to last columns and save
colnames(ROCCAdata)[93] <- "Dc_Dd"
colnames(ROCCAdata)[94] <- "Gm"
colnames(ROCCAdata)[95] <- "Pc"
colnames(ROCCAdata)[96] <- "Sa"
colnames(ROCCAdata)[97] <- "Sb"
colnames(ROCCAdata)[98] <- "Sc"
colnames(ROCCAdata)[99] <- "Sl"
colnames(ROCCAdata)[100] <- "Tt"

#Reexamining whistles with outlying values of slope means
# test<- filter(ROCCAdata, FREQPOSSLOPEMEAN  > 90000)
# test2<- filter(ROCCAdata, FREQNEGSLOPEMEAN <  -90000)

#Remove unnecessary columns

#pcdata <- ROCCAdata[, -c(1:3, 5:7, 11:13, 21, 22, 34:37, 69:92, 101)]
pcdata <- ROCCAdata[, -c(1:3, 5:7, 11:13, 21, 22, 34:37, 68:92, 101)]  #same as PvsM random forest

pcdata %>% mutate_if(is.factor, as.character) -> pcdata
# pcdata %>% mutate_if(is.character, as.factor) -> pcdata


#i <- sapply(pcdata, is.factor)
#pcdata[i] <- lapply(pcdata[i], as.character)


###Added group column manually
###Add Population column and reorder
pcdata$population <-NA
levels(pcdata$population) <- c(levels(pcdata$population), "pel", "mhi", "nwhi")
pcdata[pcdata$group %in% c(31:34), "population"] <- "mhi"
pcdata[pcdata$group %in% c(14:17), "population"] <- "nwhi"
pcdata[pcdata$group %in% c(1:8), "population"] <- "pel"
pcdata$population <- as.factor(pcdata$population)
pcdata<- pcdata[, c(61, 1:60)]

#8/29/18
levels(ROCCAdata$population) <- c(levels(ROCCAdata$population), "mhi", "other")
ROCCAdata[ROCCAdata$group %in% c(14:17), "population"] <- "other"
ROCCAdata[ROCCAdata$group %in% c(1:8), "population"] <- "other"
write.csv(ROCCAdata, 'C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\2017- 100 New Whistles/ROCCA Towed Data/BigRoccaFile_MvsOTHER_TowedAll_EDIT_20180816.csv', row.names=F)


#save file
write.csv(pcdata, 'C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\2017- 100 New Whistles/ROCCA Towed Data/BigRoccaFile_PMN_TowedAll_EDIT_20180816.csv', row.names=F)
```

Correlation Stuff
```{r}
##Calculate Pearson's correlation coefficient for all variables. Remove #variables -0.70 > r > 0.70.
pcdata <- read.csv('C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\2017- 100 New Whistles/ROCCA Towed Data/BigRoccaFile_PMN_TowedAll_EDIT_20180809.csv')
pcsub<-pcdata[,7:53]
corrplot.mixed(cor(pcsub, method= "pearson"), upper="number", lower="circle")
tmp <- cor(pcsub)
tmp[upper.tri(tmp)] <- 0
diag(tmp) <- 0
pcsubcor <- pcsub[,!apply(tmp,2,function(x) any(x > 0.80 | x < -0.80))]

# cormatrix <- rcorr(as.matrix(pcsubcor))  #creates correlation matrix with signif levels (p-values)
# cormatrix[upper.tri(cormatrix)] <- 0


#can print tmp as csv to look at pearson coefficients
#write.csv(tmp, 'C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\results/Correlation_20180809.csv', row.names = F)


  pcdata <- cbind(pcdata[, c(1:6)], pcsubcor)
  corrplot.mixed(cor(pcdata[,7:31]), upper="circle", lower="number") # for a visual representation of the correlation
  
write.csv(pcdata, 'C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\pcdata_20180809.csv', row.names = F)  
  
```


#Set up encounters for RF
```{r}
##Uncorrelated variables for all Random Forests
#pcdata<-read.csv('C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\pcdata_20180809.csv')



#Laptop directory
pcdata.mo <- read.csv('C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\2017- 100 New Whistles/ROCCA Towed Data/BigRoccaFile_MvsOTHER_TowedAll_EDIT_20180816.csv')



#desktop directory
#pcdata <- read.csv('C:\\Users\\yvers\\Documents\\CHP1\\BigRoccaFile_PMN_TowedAll_EDIT_20180816.csv')

#Remove MHI29, cluster 4
#pcdata <-droplevels(filter(pcdata, EncounterID != 'PcMHI29'))

# Need even number of encounters for each population represented in the training data. 
OTHER = c(1:8, 14:17)                # designated groupID's assigned for each pelagic group 
#NWHI  = 14:17   # designated groupID's assigned for each NWHI group, #20 was absorbed into #19 (June 2017)     
MHI = c(31:34)    # designated groupID's assigned for each MHI group, #25 absorbed into #26 (June 2017) 
                              # Oct 7: more combining of NWHI and MHI occurred. Performed in Pc_DatManipulation.rmd

nrep  = 4           # multiplier for total number of groups
nother  = 1           # number of pelagic schools to group together
nnwhi = 1           # number of northwest HI schools to group together
nmhi  = 1           # number of main HI schools to group together
w = 150              # Number of whistles randomly pulled from each group 
ntest = 1           # number of groups to randomly pull for test dataset
n_samps = 100         #number of times you want to resample from your dataset


```


Meat of the Analysis

```{r message=FALSE, warning=FALSE}

ptm<-proc.time() 


#### Start Main Analysis ####
results.mo = matrix(0, nrow = 2, ncol = 2)
output_ModelFit.mo = NULL
realP.mo = c()
realM.mo = c()
#use this format of output_WhistleClass on desktop (R version 3.3.1)
#output_WhistleClass.mo = NULL
#use this format of output_WhistleClass on laptop (R version 3.5.1)
output_WhistleClass.mo = data.frame(Doubles=double(),
                 Ints=integer(),
                 Factors=factor(),
                 Logicals=logical(),
                 Characters=character(),
                 stringsAsFactors=FALSE)
output_EncounterClass.mo=NULL
output_Results.mo=NULL
output_TrainSetAll.mo=NULL
output_TestSetAll.mo = NULL
output_Votes.moAll=NULL
tunedAll.mo=NULL
output_varIMPtotal.mo = NULL
fit_error_rate.mo = c()
accuracies.mo = c()
#fit.mo <- vector("list", n_samps)
#conf.mat.mo = matrix(0, nrow = 2, ncol = 2)
# names.test=NULL
# names.train=NULL
#output_IndDWAll=NULL

#### OVERALL LOOP TO DERIVE MEANS AND STANDARD DEVS ####  
for(rep in 1:n_samps){ 
 
  set.seed(rep) #YB placed the seed inside the loop bc it wasn't duplicating trees
  
  # Total groups included
  #This randomly samples 'nrep' groups from each population
  N_other = as.numeric(sample(OTHER, nrep*nother))
  N_mhi  = as.numeric(sample(MHI, nrep*nmhi))
  #N_nwhi  = as.numeric(sample(NWHI, nrep*nnwhi))
 
  
  # Test data 
  #Randomly sample 1 group out of the selected groups for each population to be included in the test dataset later
  test_other= as.integer(sample(N_other, ntest))
  test_mhi= as.integer(sample(N_mhi, ntest))

  
  #Combines test groups into single vector
  N_test = rbind(test_other, test_mhi)
  
  all.mo = NULL
  for(k in c(N_other,N_mhi)){
    sub=subset(pcdata.mo, pcdata.mo$group==k) #selects all whistles from the randomly selected groups, drops empty levels too
    samp=sub[sample(nrow(sub), w),] #randomly samples w whistles from the 50 or more whistles
    all.mo <-rbind(all.mo, samp)
    
    }
  #Correlation Step####
pcsub.mo<-all.mo[,7:53]
#corrplot.mixed(cor(pcsub, method= "pearson"), upper="number", lower="circle")
tmp.mo <- cor(pcsub.mo)
tmp.mo[upper.tri(tmp.mo)] <- 0
diag(tmp.mo) <- 0
pcsubcor.mo <- pcsub.mo[,!apply(tmp.mo,2,function(x) any(x > 0.80 | x < -0.80))]

all.mo <- cbind(all.mo[, c(1:6)], pcsubcor.mo)
  

test.mo<-droplevels(subset(all.mo, group%in%N_test ))
train.mo<-droplevels(subset(all.mo, !(group%in%N_test)))


#### Tuning parameters ####
## Set up a dataframe where each row is a specific combination of mtry (# of variables selected at each split), n_tree (# of trees in  forest), possibly other stuff
mtry_vals = 5:8
ntree_vals = seq(500,5000,500) #from, to, by
tune_settings = expand.grid(mtry = mtry_vals, ntree = ntree_vals)#, nodesize = node_vals)
#tune_settings2 = expand.grid(mtry = mtry_vals, ntree = ntree_vals)

#### Run Optimization Sequence ####
## Initiate Cluster

cl = makeCluster(detectCores())
registerDoParallel(cl, cores = detectCores())


#### Formula ####
# for the RF model with 'population' as the response and time-frequency measurements 

formPc.mo <- as.formula(paste("population ~ ", paste(names(all.mo)[7:length(all.mo)],collapse="+")))


## TOP 5 UNCORRELATED VARIABLES
#formPc <- as.formula(paste("population ~ ", paste(names(pcdata.mo)[7:11],collapse="+")))

## CORRELATED VARIABLES
#formPc <- as.formula(paste("population ~ ", paste(names(pcdata.mo)[7:54],collapse="+"))) #Use variables to classify to population



##The foreach function is the loop function for parallel processing. 
##It uses %dopar% which partitions the loop among your cores, then combines each output using the .combine argument. 

x.mo = foreach(i = 1:nrow(tune_settings), .combine = rbind) %dopar% { 
    library(randomForest)
    do_RF = randomForest(formPc.mo, data = train.mo, test = test.mo, ntree = tune_settings$ntree[i], mtry = tune_settings$mtry[i])#, nodesize = tune_settings$nodesize[i])
    print(do_RF$err.rate[tune_settings$ntree[i],])
  }

#so, for each of the parameter combinations, i.e., rows of the tune_settings df, the RF is run using those 
#settings (line 188) and the error rates for the 3 pop's and the oob are printed (line 189). 
#when all the rows are finished, the results are combined using the rbind function into one matrix, stored as x.

#NB: .combine can be anything, really, for example .combine = c for a vector, .combine = list for a list, etc.


#### Stop Cluster ####

stopCluster(cl)

## Combine settings and results ####

tune_settings.mo = cbind(tune_settings, x.mo)


## Optimal Settings: the settings combo
## that has the lowest OOB rate

tuned.mo<-tune_settings.mo[which.min(tune_settings.mo$OOB),]
tunedAll.mo <- rbind(tunedAll.mo, tuned.mo)

#### Run Random Forest ####
##Run Random Forest model using 'tuned' parameters for mtry and ntree
  fit.mo <- randomForest(formPc.mo, data=train.mo, ntree=tuned.mo[1,2], importance=TRUE, replace=T, mtry=tuned.mo[1,1], norm.votes=F, confusion=T, keep.inbag=T, proximity=T, keep.forest=T, scale = F) 



#prediction for population of test data using RF model, 'fit', returns a list with aggregate and individual votes for each whistle  
  prediction.mo <-predict(fit.mo, newdata=test.mo, predict.all = F, type='response', nodes = T) 
  prediction.vote <-predict(fit.mo, newdata=test.mo, predict.all = T, type='vote')

   #shows T/F for individual whistles and whether they were classified correctly  
   test.mo$rightPred <- as.character(prediction.mo) == as.character(test.mo$population) 
  
   #sums all 'TRUE' and divides by total
   accuracy.mo <- sum((test.mo$rightPred)/nrow(test.mo)) 
   accuracies.mo <- c(accuracies.mo, accuracy.mo)
  ####RESULTS!!!#####  
  results.motemp <- table(test.mo$population, prediction.mo)  # conf matrix of individual whistle counts
  
## Get percentages of whistles correctly and incorrectly classified   
  #calculate % accuracies of diagonal by population from confusion matrix of percentages
mo.mo<-round((results.motemp[1,1])/(results.motemp[1,1]+results.motemp[1,2])*100,2) #pelagic
mhi.mhi<-round((results.motemp[2,2])/(results.motemp[2,1]+results.motemp[2,2])*100,2) #mhi 
  #calculate misclassification for pelagic
mo.mhi<-round((results.motemp[1,2])/(results.motemp[1,1]+results.motemp[1,2])*100,2)
mhi.mo<-round((results.motemp[2,1])/(results.motemp[2,1]+results.motemp[2,2])*100,2) 
  

#Consolidate back into confusion matrix
mo.row<-c(mo.mo, mo.mhi)
#nwhi.row<-c(nwhi.mo, nwhi.nwhi, nwhi.mhi)
mhi.row<-c(mhi.mo, mhi.mhi)
#class.title<-c('pelagic', 'mhi')
conf.mat.mo <- rbind(mo.row, mhi.row) #(% of whistles)
#conf.mat.mo = conf.mat.mo + conf.mat.motemp
#conf.mat.mo<-data.frame(rbind("Pelagic"=pel.row, "MHI"=mhi.row))


colnames(conf.mat.mo)=c("Other", "MHI")
#conf.mat.mo

true.mo = if(mo.mo>=60) 'Other' else 'Ambiguous'
#true.nwhi = if(nwhi.nwhi>50) 'NWHI' else 'Ambiguous'
true.mhi = if(mhi.mhi>=60) 'MHI' else 'Ambiguous'
true.enc.mo = data.frame(rbind(mo.mo, mhi.mhi))
#d = as.data.frame(unique(test$EncounterID))
#d = as.data.frame(d[c(1:3), ])
e.mo=c()
e.mo=as.data.frame(rbind(true.mo, true.mhi))
e.mo=cbind(e.mo, true.enc.mo)
colnames(e.mo) = c("EncounterClass", "PctCorrect") #, "EncounterID")

#Summed results confusion matrix after each iteration
results.mo = results.mo + results.motemp 

#For calculating means and standard dev for EACH ITERATION of confusion matrix
#For a single iteration, stores separate cells of class results for calculating mean and standard error
#YOU NEED THIS STEP 4/26/18, TRUST ME!
realP.mo <- c(realP.mo,results.motemp[1,1])
#fakeP <- c(fakeP,results.motemp[1,2])
realM.mo <- c(realM.mo,results.motemp[2,2])
#fakeM <- c(fakeM,results.motemp[2,1])
        
#### OUTPUTS ####
#1.
#Save each RF model's confusion matrix and OOB error
output_ModelFit.mo <- rbind(output_ModelFit.mo, as.table(fit.mo$confusion), mean(fit.mo$err.rate))

#2.
#Most comprehensive information about overall predictions, proportional classification of trees, and tree predictions for each whistle
g.mo=cbind(rep, "EncounterID"= test.mo$EncounterID, "EncounterCount"=test.mo$EncounterCount, "Prediction"=test.mo$rightPred, "PredictedPop"=prediction.mo,as.data.frame(cbind(prediction.vote$aggregate, prediction.vote$individual)))

output_WhistleClass.mo <- bind_rows(list(output_WhistleClass.mo, g.mo), .id = 'id')

#3.
#table keeping track of confusion matrices for all iterations
output_Results.mo<-rbind(output_Results.mo, rep, results.motemp, accuracy.mo=signif(accuracy.mo, digits = 3)) 

#4.
#Output of encounters used in each training set  
output_TrainSet.mo <- data.frame(rep, "EncounterID" = sort(unique(train.mo$EncounterID))) #, "encounter" = sort(unique(train$group)))
output_TrainSetAll.mo <-rbind(output_TrainSetAll.mo, output_TrainSet.mo)

#5.
#Output shows encounters in each test set, encounter prediction, and % correctly classified
output_TestSet.mo <- data.frame(rep, "EncounterID" = sort(unique(test.mo$EncounterID)), e.mo) #, "encounter" = sort(unique(train$group)))
output_TestSetAll.mo <-rbind(output_TestSetAll.mo, output_TestSet.mo)

#6.
  # Important Variables
  varIMPtemp.mo <- as.data.frame(importance(fit.mo))
  varIMP.mo <- varIMPtemp.mo[order(varIMPtemp.mo$MeanDecreaseGini), , drop =F]
  output_varIMPtotal.mo <- rbind(output_varIMPtotal.mo, "REP"=rep, varIMP.mo)



}

#7.
#Overall correct classification scores
correctP.mo <- round((results.mo[1,1]/(results.mo[1,1]+results.mo[1,2])*100), 2)
correctM.mo <- round((results.mo[2,2]/(results.mo[2,1]+results.mo[2,2])*100), 2)

output_CorrectClass.mo <- rbind(results.mo,cbind(correctP.mo, correctM.mo))




proc.time() - ptm
``` 
 
 
 #For laptop directories

```{r}
se <- function(x) sd(x)/sqrt(length(x))

meanRealP <- mean(realP.mo)
meanRealM <- mean(realM.mo)
seRealP <- se(realP.mo)
seRealM <- se(realM.mo)

 
date='20180829'
#Combine means and std errors into matrix
sink("C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018\\ConfMatrixMO_means_20180829.txt", append=T)
PNMmeans.mo <- cbind("PEL"= c(meanRealP), "MHI"=c(meanRealM)) #means
PNMse.mo <- cbind("PEL"= c(seRealP), "MHI"=c(seRealM)) #standard errors
PNMtotal.mo <- rbind("Means" = PNMmeans.mo, "Stand Err" = PNMse.mo)

date
w
n_samps
PNMtotal.mo
sink()


```


###Write NEW WHISTLE DATA outputs to file
```{r}

#Save overall confusion matrix
write.table(output_CorrectClass.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018\\PcResults_ConfusionMatrix_MvsOther_20180829.csv", append = T, row.names = T, col.names=T, sep = ",")

write.table(output_Results.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018\\PcResults_TotalResults_MvsOther_20180829.csv", append = T, row.names = T, col.names=T, sep = ",")

write.table(output_WhistleClass.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018/PcResults_TotalWhistleClass_MvsOther_20180829.csv", append = T, row.names = F, col.names=T, sep = ",")

write.table(output_TrainSetAll.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018/PcResults_TrainSets_MvsOther_20180829.csv", append = T, col.names=T, sep = ",")

write.table(output_TestSetAll.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018/PcResults_TestResults_MvsOther_20180829.csv", append = T, col.names=T, sep = ",")

write.table(output_varIMPtotal.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018/PcResults_ImportantVars_MvsOther_20180829.csv", append = T, col.names=T, sep = ",")

write.table(tunedAll.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018/PcResults_TunedParameters_MvsOther_20180829.csv", append = T, col.names=T, sep = ",")

write.table(output_ModelFit.pm, "C:\\Users\\Yvonne\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018/PcResults_TotalModels_MvsOther_20180829.csv", append = T, col.names=F, sep = ",")

```
 