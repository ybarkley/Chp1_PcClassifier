---
title: "Totally Random RandomForest"
author: "Yvonne Barkley"
date: "July 21, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r warning=FALSE, message=FALSE}

library(randomForest)
library(party)
library(caret)
library(corrplot)
library(parallel); 
library(doParallel);
library(gtools)
library(devtools) 
library(dplyr)
library(data.table)
library(ggplot2)
library(gtools)


```

```{r}
#pcdata <- read.csv('C:\\Users\\yvonne.barkley\\Documents\\PHD\\Chp1_PcClassifier-master\\BIG ROCCA FILE.csv')
# pcdata <-read.csv('C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\2017- 100 New Whistles/BIG ROCCA FILE.csv')
# pcdata <- droplevels(filter(pcdata, population != "nwhi"))

#7/20/18
#pcdata <- read.csv('C:\\Users\\Yvonne\\Documents\\PHD\\CHP1-FKW\\data\\results\\20180717\\pcdata.pm_uncorrelated_20180717.csv')

#3/16/19
pcdata <- read.csv('data/BigRoccaFile_PMN_TowedAll_EDIT_20181124.csv')

PEL = 1:8                # designated groupID's assigned for each pelagic group 
NWHI  = 14:17   # designated groupID's assigned for each NWHI group, #20 was absorbed into #19 (June 2017)     
MHI = 31:34    # designated groupID's assigned for each MHI group, #25 absorbed into #26 (June 2017) 
                              # Oct 7: more combining of NWHI and MHI occurred. Performed in Pc_DatManipulation.rmd
#This is set up to be flexible to change later if needed
nrep  = 4          
npel  = 1           # number of pelagic schools to group together
#nnwhi = 1           # number of northwest HI schools to group together
nmhi  = 1           # number of main HI schools to group together
w = 150              # Number of whistles randomly pulled from each group 
ntest = 1           # number of groups to randomly pull for test dataset
n_samps = 100        #Zack: number of times you want to resample from your dataset
prop = 0.75          #proportion of whistles in training data
```


```{r}
####Start####


ptm <- proc.time()

results.tots = matrix(0, nrow = 12, ncol = 3) #based on total # of groups
output_ModelFit.tots = NULL
output_WhistleClass.tots =NULL
output_Results.tots=NULL
output_TrainSettots_rand=NULL
output_TestSettots_rand = NULL
output_Votestots_rand=NULL
tunedtots_rand=NULL
output_varIMPtotal.tots =NULL
accuracies.tots = c()


## GIANT LOOP---BEWARE ####

for(rep in 1:n_samps){

#7/20/18 This is a totally random RF using the same partitioning as the Encounter Classifier

  
#Randomly select only 4 out of 8 pelagic encounters  
 N_pel = as.numeric(sample(PEL, nrep*npel))
 
 
  

  
#From all encounters, sample 'prop' whistles from each encounter
tots_rand = NULL
for(i in c(N_pel, NWHI, MHI)){
  sub.tots=droplevels(subset(pcdata, pcdata$group==i)) #selects all whistles from the randomly selected groups, drops empty levels too
  samp.tots=sub.tots[sample(nrow(sub.tots), w),] #randomly samples w whistles from total whistles
  tots_rand <-rbind(tots_rand, samp.tots) #mixed up list of whistles
  
}

  #Correlation Step####
pcsub.tots<-tots_rand[,7:53]
#corrplot.mixed(cor(pcsub, method= "pearson"), upper="number", lower="circle")
tmp.tots <- cor(pcsub.tots)
tmp.tots[upper.tri(tmp.tots)] <- 0
diag(tmp.tots) <- 0
pcsubcor.tots <- pcsub.tots[,!apply(tmp.tots,2,function(x) any(x > 0.80 | x < -0.80))]

tots_rand<- cbind(tots_rand[, c(1:6)], pcsubcor.tots)


part.tots <- createDataPartition(y=tots_rand$EncounterID,p=prop,list=FALSE)
train.tots <- tots_rand[part.tots,]  
test.tots <- tots_rand[-part.tots,]




## Set up a dataframe where each row is a specific 
## combination of mtry (# of variables selected at each split), n_tree (# of trees in  forest), possibly other stuff

mtry_vals = sqrt(length(tots_rand[,7:length(tots_rand)]))  
ntree_vals = seq(501,5001,500) #from, to, by
tune_settings = expand.grid(mtry = mtry_vals, ntree = ntree_vals)


## Initiate Cluster

cl = makeCluster(detectCores())
registerDoParallel(cl, cores = detectCores())


##Create the formula for the RF model with 'population' as the response and time-frequency measurements from uncorrelated data as the covariates

#formPc.new <- as.formula(paste("population ~ ", paste(names(pcnew)[7:36],collapse="+")))
formPc.tots <- as.formula(paste("population ~ ", paste(names(tots_rand)[7:length(tots_rand)],collapse="+"))) #Use variables to classify to encounter


##The foreach function is the loop function for parallel processing. 
##It uses %dopar% which partitions the loop among your cores, then combines each output using the .combine argument. 

x = foreach(i = 1:nrow(tune_settings), .combine = rbind) %dopar% { 
  library(randomForest)
  do_RF2 = randomForest(formPc.tots, data = train.tots, test = test.tots, ntree = tune_settings$ntree[i], mtry = tune_settings$mtry[i])
  print(do_RF2$err.rate[tune_settings$ntree[i],])
}

#so, for each of the parameter combinations, i.e., rows of the tune_settings df, the RF is run using those 
#settings (line 46) and the error rates for the 3 pop's and the oob are printed (line 47). 
#when all the rows are finished, the results are combined using the rbind function into one matrix, stored as x.

#NB: .combine can be anything, really, for example .combine = c for a vector, .combine = list for a list, etc.


## Stop Cluster

stopCluster(cl)


## Combine settings and results

tune_settings.tots = cbind(tune_settings, x)

## Optimal Settings: the settings combo
## that has the lowest OOB rate

tuned.tots<-tune_settings.tots[which.min(tune_settings.tots$OOB),]
tunedtots_rand <- rbind(tunedtots_rand, tuned.tots)
 
### RANDOM FOREST ####


##Run Random Forest model using 'tuned' parameters for mtry and ntree
fit.tots <- randomForest(formPc.tots, data=train.tots, ntree=tuned.tots[1,2], importance=TRUE, replace=T, mtry=tuned.tots[1,1], norm.votes=T, confusion=T, keep.inbag=T, proximity=T) 

prediction.tots <-predict(fit.tots, newdata=test.tots, predict.all = F, type='response') #prediction of test data using RF model, 'fit'
prediction_vote.tots <-predict(fit.tots, newdata=test.tots, predict.all = T, type='vote') #prediction of test data using RF model, 'fit'
test.tots$rightPred <- as.character(prediction.tots) == as.character(test.tots$EncounterID) #shows T/F for individual whistles and whether they were classified correctly
accuracy.tots <- sum((test.tots$rightPred)/nrow(test.tots)) #sums all 'TRUE' and divides by total
accuracies.tots <- c(accuracies.tots, accuracy.tots)

###RESULTS!!!##################################  
results.totstemp <- table(test.tots$population, prediction.tots)    

results.tots <- results.tots + results.totstemp  


pel.nwhi.totstemp = sum(results.totstemp[1,2],results.totstemp[2,2],results.totstemp[3,2],results.totstemp[4,2])
pel.mhi.totstemp =  sum(results.totstemp[1,3],results.totstemp[2,3],results.totstemp[3,3],results.totstemp[4,3])

nwhi.pel.totstemp = sum(results.totstemp[5:8])
nwhi.mhi.totstemp = sum(results.totstemp[5,3],results.totstemp[6,3],results.totstemp[7,3],results.totstemp[8,3])

mhi.pel.totstemp =  sum(results.totstemp[9:12])
mhi.nwhi.totstemp = sum(results.totstemp[9,2],results.totstemp[10,2],results.totstemp[11,2],results.totstemp[12,2])

pel.pel.totstemp = round(sum(results.totstemp[1:4])/(sum(results.totstemp[1:4])+pel.nwhi.totstemp+pel.mhi.totstemp)*100,2)
nwhi.nwhi.totstemp = round(sum(results.totstemp[5,2],results.totstemp[6,2],results.totstemp[7,2],results.totstemp[8,2])/(sum(results.totstemp[5,2],results.totstemp[6,2],results.totstemp[7,2],results.totstemp[8,2])+nwhi.pel.totstemp+nwhi.mhi.totstemp)*100,2)
mhi.mhi.totstemp = round(sum(results.totstemp[9,3],results.totstemp[10,3],results.totstemp[11,3],results.totstemp[12,3])/(sum(results.totstemp[9,3],results.totstemp[10,3],results.totstemp[11,3],results.totstemp[12,3])+mhi.pel.totstemp+mhi.nwhi.totstemp)*100,2)


#Set a threshold for the percentage of whistles that must be correctly classified to classify the population
true.pel.tots = if(pel.pel.totstemp >= 50) 'Pelagic' else 'Ambiguous'
true.nwhi.tots = if(nwhi.nwhi.totstemp >= 50) 'NWHI' else 'Ambiguous'
true.mhi.tots = if(mhi.mhi.totstemp >= 50) 'MHI' else 'Ambiguous'

true.tots.tots = data.frame(rbind(pel.pel.totstemp, nwhi.nwhi.totstemp,mhi.mhi.totstemp))

e.tots=c()
e.tots=as.data.frame(rbind(true.pel.tots, true.nwhi.tots, true.mhi.tots))
e.tots=cbind(e.tots, true.tots.tots)
colnames(e.tots) = c("EncounterClass", "Pct Correct") 




#### OUTPUTS ####

#1.
output_ModelFit.tots <- rbind(output_ModelFit.tots, as.table(fit.tots$confusion), mean(fit.tots$err.rate))

#2.
#Save results for each individual whistle, including overall predictions based on majority vote of forest and individual tree predictions
# g.tots=cbind(rep, "EncounterID"= test.tots$EncounterID, "EncounterCount"=test.tots$EncounterCount, "Prediction"=test.tots$rightPred, "PredictedPop"=prediction.tots, as.data.frame(cbind(prediction_vote.tots$aggregate, prediction_vote.tots$individual))) 

#output_WhistleClass.tots <- smartbind(output_WhistleClass.tots, g.tots, fill = NA, sep=':')

#3.
#table keeping track of individual confusion matrices for all iterations
output_Results.tots<-rbind(output_Results.tots, rep, results.totstemp, accuracy=signif(accuracy.tots, digits = 3)) 

#4.
#df to show encounters used in each training set  
output_TrainSettots_rand <- data.frame(rep, "EncounterID" = sort(unique(train.tots$EncounterID))) #, "encounter" = sort(unique(train$group)))
output_TrainSettots_rand <-rbind(output_TrainSettots_rand, output_TrainSettots_rand)

#5.
#df to show encounters used in each test set
output_TestSet.tots <- data.frame(rep, "EncounterID" = unique(test.tots$EncounterID), e.tots) #, "encounter" = sort(unique(train$group)))
output_TestSettots_rand <-rbind(output_TestSettots_rand, output_TestSet.tots)


#6.
# Important Variables
  varIMPtemp.tots <- as.data.frame(importance(fit.tots))
  varIMP.tots <- varIMPtemp.tots[order(varIMPtemp.tots$MeanDecreaseGini), , drop =F]
  output_varIMPtotal.tots <- rbind(output_varIMPtotal.tots, "REP"=rep, varIMP.tots)

}

#Manipulate results.tots, every 4 rows represents a different true population
pel.pel.tots = sum(results.tots[1:4])
pel.nwhi.tots = sum(results.tots[1,2],results.tots[2,2],results.tots[3,2],results.tots[4,2])
pel.mhi.tots = sum(results.tots[1,3],results.tots[2,3],results.tots[3,3],results.tots[4,3])

nwhi.pel.tots = sum(results.tots[5:8])
nwhi.nwhi.tots = sum(results.tots[5,2],results.tots[6,2],results.tots[7,2],results.tots[8,2])
nwhi.mhi.tots = sum(results.tots[5,3],results.tots[6,3],results.tots[7,3],results.tots[8,3])

mhi.pel.tots = sum(results.tots[9:12])
mhi.nwhi.tots = sum(results.tots[9,2],results.tots[10,2],results.tots[11,2],results.tots[12,2])
mhi.mhi.tots = sum(results.tots[9,3],results.tots[10,3],results.tots[11,3],results.tots[12,3])

#Consolidate back into confusion matrix with correct class scores
pel.row.tots = c(pel.pel.tots, pel.nwhi.tots, pel.mhi.tots)
nwhi.row.tots = c(nwhi.pel.tots, nwhi.nwhi.tots, nwhi.mhi.tots)
mhi.row.tots = c(mhi.pel.tots, mhi.nwhi.tots, mhi.mhi.tots)

correctP.tots = round((pel.pel.tots/sum(pel.pel.tots,pel.nwhi.tots,pel.mhi.tots)*100), 2)
correctN.tots = round((nwhi.nwhi.tots/sum(nwhi.pel.tots,nwhi.nwhi.tots,nwhi.mhi.tots)*100), 2)
correctM.tots = round((mhi.mhi.tots/sum(mhi.pel.tots,mhi.nwhi.tots,mhi.mhi.tots)*100), 2)

conf.mat.tots <-data.frame(rbind("Pelagic"=pel.row.tots, "NWHI"=nwhi.row.tots, "MHI"=mhi.row.tots, cbind(correctP.tots,correctN.tots,correctM.tots)))

colnames(conf.mat.tots)=c("Pelagic", "NWHI", "MHI")







proc.time()-ptm
```





```{r}

write.table(conf.mat.tots, "data/results/PcResults_ConfusionMatrix_TotesRandom_20190316.csv", append = T, row.names = T, col.names=T, sep = ",")

write.table(output_Results.tots, "data\\results\\PcResults_TotalResults_TotesRandom_20190316.csv", append = T, row.names = T, col.names=T, sep = ",")

write.table(output_WhistleClass.tots, "data\\results\\PcResults_TotalWhistleClass_TotesRandom_20190316.csv", append = T, row.names = F, col.names=T, sep = ",")

write.table(output_TrainSettots_rand, "data\\results\\PcResults_TrainSets_TotesRandom_20190316.csv", append = T, col.names=T, sep = ",")

write.table(output_TestSettots_rand, "data\\results\\PcResults_TestResults_TotesRandom_20190316.csv", append = T, col.names=T, sep = ",")

write.table(output_varIMPtotal.tots, "data\\results\\PcResults_ImportantVars_TotesRandom_20190316.csv", append = T, col.names=T, sep = ",")

write.table(tunedtots_rand, "C:\\Users\\yvers\\OneDrive\\PHD\\CHP1-FKW\\data\\results\\2018/PcResults_TunedParameters_TotesRandom_20180825.csv", append = T, col.names=T, sep = ",")

write.table(output_ModelFit.tots, "data\\results\\PcResults_TotalModels_TotesRandom_20190316.csv", append = T, col.names=F, sep = ",")

#raw results table
write.table(results.tots, 'data\\results\\PcResults_RawResults_TotesRandom_20190316.csv', sep=",", append=TRUE)




```

#enc_pred.table<-rbind(enc_pred.table, rep, enc_results, accuracy2=signif(accuracy2, digits = 3)) #rough table keeping track of confusion matrices for all iterations


            
enc.whistles<-data.frame("group"=enc_test$EncounterID, "prediction"=enc_prediction, "whistle"=enc_test$whistle_count)

false=nrow(subset(enc_test, enc_test$rightPred=='FALSE'))/nrow(enc_test)*100 #percentage of misclassified whistles
falsehope <- c(falsehope, false)

## OUTPUTS ####
#   d.tots = as.data.frame(unique(enc_test$id))
#   d.tots = as.data.frame(as.character(d.tots[27, ]))
#   e.tots=c()
#   e.tots=as.data.frame(rbind(true.pel.array))#, true.nwhi.array))
#   e.tots=cbind(e.tots, d.tots)
#   colnames(e.tots) = c("Classification", "EncounterID")
#   
# f.array=as.data.frame(cbind(prediction.array.vote$aggregate, prediction.array.vote$individual))
# g.array=cbind(enc, "population"=array.test$population, "group"=array.test$group, whistle=array.test$whistle_count, "prediction"=array.test$rightPred, f.array)
# 
# output_VotesAll.array <- bind_rows(output_VotesAll.array, g.array)


}
```
